{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5339ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'DEFINITION_ID', 'TIME'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/synthetic_data_lung_cancer.csv\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f38bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['condition', 'death', 'drug', 'measurement', 'observation',\n",
      "       'procedure'],\n",
      "      dtype='object', name='CATEGORY')\n"
     ]
    }
   ],
   "source": [
    "# Splitting 'DEFINITION_ID' into multiple columns\n",
    "new_cols = data['DEFINITION_ID'].str.split('_', expand=True)\n",
    "\n",
    "# Naming the new columns\n",
    "new_cols.columns = ['CATEGORY', 'CATEGORY_ID']\n",
    "\n",
    "# Pivoting the DataFrame\n",
    "pivot_new_cols = new_cols.pivot_table(index=data.index, columns='CATEGORY', values='CATEGORY_ID', aggfunc=lambda x: ', '.join(str(v) for v in x)).fillna('-1')\n",
    "\n",
    "print(pivot_new_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5261a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'TIME', 'condition', 'death', 'drug', 'measurement',\n",
      "       'observation', 'procedure'],\n",
      "      dtype='object')\n",
      "[2400, 419, 225, 491]\n",
      "[False, False, False, False]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>condition</th>\n",
       "      <th>death</th>\n",
       "      <th>drug</th>\n",
       "      <th>measurement</th>\n",
       "      <th>observation</th>\n",
       "      <th>procedure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>1922</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>785</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032515</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>132</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID      TIME condition  death drug measurement observation  \\\n",
       "0           1  0.004807        -1      0  217          -1          -1   \n",
       "1           1  0.008643      1922      0   -1          -1          -1   \n",
       "2           1  0.027792       785      0   -1          -1          -1   \n",
       "3           1  0.032515        -1      0   49          -1          -1   \n",
       "4           1  0.056765        -1      0   -1         132          -1   \n",
       "\n",
       "  procedure  \n",
       "0        -1  \n",
       "1        -1  \n",
       "2        -1  \n",
       "3        -1  \n",
       "4        -1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating the new columns to the original DataFrame\n",
    "df = pd.concat([data, pivot_new_cols], axis=1)\n",
    "\n",
    "# Dropping the original 'DEFINITION_ID' column\n",
    "df.drop(columns=['DEFINITION_ID'], inplace=True)\n",
    "\n",
    "# Filling the death column \n",
    "df['death'] = df['death'].replace('None', '1')\n",
    "df['death'] = df['death'].replace('-1', '0')\n",
    "# Converting column to boolean dtype\n",
    "df['death'] = df['death'].astype(int)\n",
    "\n",
    "print(df.columns)\n",
    "#df.loc[(df['condition']=='')&(df['drug']=='')&(df['measurement']=='')&(df['observation']=='')&(df['procedure']=='')]\n",
    "print([len(df['condition'].unique()),\n",
    "len(df['drug'].unique()),\n",
    "len(df['observation'].unique()),\n",
    "len(df['procedure'].unique())])\n",
    "\n",
    "print(['0' in (df['condition'].unique()),\n",
    "'0' in (df['drug'].unique()),\n",
    "'0' in (df['observation'].unique()),\n",
    "'0' in (df['procedure'].unique())])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0880f6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>death</th>\n",
       "      <th>condition_-1</th>\n",
       "      <th>condition_1</th>\n",
       "      <th>condition_10</th>\n",
       "      <th>condition_100</th>\n",
       "      <th>condition_1000</th>\n",
       "      <th>condition_1001</th>\n",
       "      <th>condition_1002</th>\n",
       "      <th>...</th>\n",
       "      <th>procedure_90</th>\n",
       "      <th>procedure_91</th>\n",
       "      <th>procedure_92</th>\n",
       "      <th>procedure_93</th>\n",
       "      <th>procedure_94</th>\n",
       "      <th>procedure_95</th>\n",
       "      <th>procedure_96</th>\n",
       "      <th>procedure_97</th>\n",
       "      <th>procedure_98</th>\n",
       "      <th>procedure_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032515</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4871 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID      TIME  death  condition_-1  condition_1  condition_10  \\\n",
       "0           1  0.004807      0          True        False         False   \n",
       "1           1  0.008643      0         False        False         False   \n",
       "2           1  0.027792      0         False        False         False   \n",
       "3           1  0.032515      0          True        False         False   \n",
       "4           1  0.056765      0          True        False         False   \n",
       "\n",
       "   condition_100  condition_1000  condition_1001  condition_1002  ...  \\\n",
       "0          False           False           False           False  ...   \n",
       "1          False           False           False           False  ...   \n",
       "2          False           False           False           False  ...   \n",
       "3          False           False           False           False  ...   \n",
       "4          False           False           False           False  ...   \n",
       "\n",
       "   procedure_90  procedure_91  procedure_92  procedure_93  procedure_94  \\\n",
       "0         False         False         False         False         False   \n",
       "1         False         False         False         False         False   \n",
       "2         False         False         False         False         False   \n",
       "3         False         False         False         False         False   \n",
       "4         False         False         False         False         False   \n",
       "\n",
       "   procedure_95  procedure_96  procedure_97  procedure_98  procedure_99  \n",
       "0         False         False         False         False         False  \n",
       "1         False         False         False         False         False  \n",
       "2         False         False         False         False         False  \n",
       "3         False         False         False         False         False  \n",
       "4         False         False         False         False         False  \n",
       "\n",
       "[5 rows x 4871 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummies for categorical analysis\n",
    "\n",
    "df = pd.get_dummies(df,columns=['condition','drug','measurement','observation','procedure'])\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cebc9cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: death, dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>condition_1</th>\n",
       "      <th>condition_10</th>\n",
       "      <th>condition_100</th>\n",
       "      <th>condition_1000</th>\n",
       "      <th>condition_1001</th>\n",
       "      <th>condition_1002</th>\n",
       "      <th>condition_1003</th>\n",
       "      <th>condition_1004</th>\n",
       "      <th>...</th>\n",
       "      <th>procedure_90</th>\n",
       "      <th>procedure_91</th>\n",
       "      <th>procedure_92</th>\n",
       "      <th>procedure_93</th>\n",
       "      <th>procedure_94</th>\n",
       "      <th>procedure_95</th>\n",
       "      <th>procedure_96</th>\n",
       "      <th>procedure_97</th>\n",
       "      <th>procedure_98</th>\n",
       "      <th>procedure_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032515</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4865 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID      TIME  condition_1  condition_10  condition_100  \\\n",
       "0           1  0.004807        False         False          False   \n",
       "1           1  0.008643        False         False          False   \n",
       "2           1  0.027792        False         False          False   \n",
       "3           1  0.032515        False         False          False   \n",
       "4           1  0.056765        False         False          False   \n",
       "\n",
       "   condition_1000  condition_1001  condition_1002  condition_1003  \\\n",
       "0           False           False           False           False   \n",
       "1           False           False           False           False   \n",
       "2           False           False           False           False   \n",
       "3           False           False           False           False   \n",
       "4           False           False           False           False   \n",
       "\n",
       "   condition_1004  ...  procedure_90  procedure_91  procedure_92  \\\n",
       "0           False  ...         False         False         False   \n",
       "1           False  ...         False         False         False   \n",
       "2           False  ...         False         False         False   \n",
       "3           False  ...         False         False         False   \n",
       "4           False  ...         False         False         False   \n",
       "\n",
       "   procedure_93  procedure_94  procedure_95  procedure_96  procedure_97  \\\n",
       "0         False         False         False         False         False   \n",
       "1         False         False         False         False         False   \n",
       "2         False         False         False         False         False   \n",
       "3         False         False         False         False         False   \n",
       "4         False         False         False         False         False   \n",
       "\n",
       "   procedure_98  procedure_99  \n",
       "0         False         False  \n",
       "1         False         False  \n",
       "2         False         False  \n",
       "3         False         False  \n",
       "4         False         False  \n",
       "\n",
       "[5 rows x 4865 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, create a list of unique SUBJECT_IDs\n",
    "unique_subject_ids = df['SUBJECT_ID'].unique()\n",
    "\n",
    "# Then, split the unique_subject_ids into train and test IDs\n",
    "train_ids, test_ids = train_test_split(unique_subject_ids, test_size=0.2, random_state=2)\n",
    "\n",
    "# Filter the main DataFrame into train and test sets based on the selected IDs\n",
    "train_data = df[df['SUBJECT_ID'].isin(train_ids)]\n",
    "test_data = df[df['SUBJECT_ID'].isin(test_ids)]\n",
    "\n",
    "# Separate the features (X) and target variable (y) for train and test sets\n",
    "X_train = train_data.drop('death',axis=1).drop(['condition_-1','drug_-1','measurement_-1','observation_-1','procedure_-1'],axis=1)  # Drop 'SUBJECT_ID' and target column\n",
    "y_train = pd.Series(train_data.death)\n",
    "\n",
    "X_test = test_data.drop('death',axis=1).drop(['condition_-1','drug_-1','measurement_-1','observation_-1','procedure_-1'],axis=1)  # Drop 'SUBJECT_ID' and target column\n",
    "y_test = pd.Series(test_data.death)\n",
    "#old way:\n",
    "#X = df.drop('death',axis=1).drop(['condition_-1','drug_-1','measurement_-1','observation_-1','procedure_-1'],axis=1)\n",
    "#y = pd.Series(df.death)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(y_train.head())\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b871b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 464916\n",
      "After: 464916\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "print(\"Before: \"+str(len(X_train)))\n",
    "\n",
    "#sampling \n",
    "smote_enn = SMOTEENN()\n",
    "\n",
    "\n",
    "sample_strategy =smote_enn\n",
    "\n",
    "\n",
    "#X_train, y_train = sample_strategy.fit_resample(X_train, y_train)\n",
    "print(\"After: \"+str(len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c6d2f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 13.5 GiB for an array with shape (371932, 4865) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m selector \u001b[38;5;241m=\u001b[39m RFECV(estimator\u001b[38;5;241m=\u001b[39mestimator, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# 5-fold cross-validation\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the selector on your training data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X_train_selected \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mfit_transform(X_train, y_train)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_selected\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     16\u001b[0m X_train_selected\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:725\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    722\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    723\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m--> 725\u001b[0m scores \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    726\u001b[0m     func(rfe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y, train, test, scorer)\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    728\u001b[0m )\n\u001b[0;32m    730\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[0;32m    731\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:726\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    722\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    723\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[0;32m    725\u001b[0m scores \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m--> 726\u001b[0m     func(rfe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y, train, test, scorer)\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    728\u001b[0m )\n\u001b[0;32m    730\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[0;32m    731\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:37\u001b[0m, in \u001b[0;36m_rfe_single_fit\u001b[1;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[0;32m     35\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[0;32m     36\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rfe\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m     38\u001b[0m     X_train,\n\u001b[0;32m     39\u001b[0m     y_train,\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m estimator, features: _score(\n\u001b[0;32m     41\u001b[0m         estimator, X_test[:, features], y_test, scorer\n\u001b[0;32m     42\u001b[0m     ),\n\u001b[0;32m     43\u001b[0m )\u001b[38;5;241m.\u001b[39mscores_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 299\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X[:, features], y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    302\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    303\u001b[0m     estimator,\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    305\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    306\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1197\u001b[0m     X,\n\u001b[0;32m   1198\u001b[0m     y,\n\u001b[0;32m   1199\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1200\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[0;32m   1201\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1202\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1203\u001b[0m )\n\u001b[0;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 13.5 GiB for an array with shape (371932, 4865) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression  # Replace with an appropriate estimator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize your estimator (e.g., Logistic Regression)\n",
    "lr=LogisticRegression(penalty='l1',solver='liblinear')\n",
    "svc=SVC(kernel=\"linear\")\n",
    "nb=GaussianNB()\n",
    "\n",
    "estimator = LogisticRegression(penalty='l1',solver='liblinear')  #change to whatever works best\n",
    "\n",
    "# Initialize RFECV with the estimator and scoring method\n",
    "selector = RFECV(estimator=estimator, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Fit the selector on your training data\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "print(X_train_selected.columns)\n",
    "X_train_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# no scaling necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b099fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model\n",
    "rf = RandomForestClassifier(n_estimators=100,criterion=\"gini\",max_features=100,max_depth=4)\n",
    "model = rf\n",
    "\n",
    "#fit model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Limit the number of features to display (top 100)\n",
    "top_n = 100\n",
    "indices = indices[:top_n]\n",
    "feature_importances = feature_importances[indices]\n",
    "feature_names = feature_names[indices]\n",
    "\n",
    "# Plot feature importances (top 100)\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title(\"Top 100 Feature Importances\")\n",
    "plt.bar(range(top_n), feature_importances, align=\"center\")\n",
    "plt.xticks(range(top_n), feature_names, rotation=90)\n",
    "plt.xlabel(\"Feature Names\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ff568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#cross validation\n",
    "scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "probs = pd.DataFrame(probs)\n",
    "probs = pd.Series(probs.iloc[:, 1])\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test.values, probs)\n",
    "print(\"AUC:\", auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
