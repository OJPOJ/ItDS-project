{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8029002e",
   "metadata": {},
   "source": [
    "<h1>Predictive Model LCSF1: Lung Cancer Survival Forecasting for 1 Year</h1>\n",
    "\n",
    "\n",
    "<h4>Workflow</h4><br>\n",
    "<p>Here we lay out our thought process and what we did, while building a predictive model for lung cancer survival.</p>\n",
    "<p></p>\n",
    "<p>First we assume, that we have a choice of including a selection of more and / or less frequent </p>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f0891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5339ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'DEFINITION_ID', 'TIME'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DEFINITION_ID</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560966</th>\n",
       "      <td>984</td>\n",
       "      <td>measurement_1141</td>\n",
       "      <td>0.027321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560967</th>\n",
       "      <td>984</td>\n",
       "      <td>observation_156</td>\n",
       "      <td>0.028739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560968</th>\n",
       "      <td>984</td>\n",
       "      <td>measurement_1140</td>\n",
       "      <td>0.030802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560969</th>\n",
       "      <td>984</td>\n",
       "      <td>measurement_1327</td>\n",
       "      <td>0.035081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560970</th>\n",
       "      <td>984</td>\n",
       "      <td>condition_459</td>\n",
       "      <td>0.038022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SUBJECT_ID     DEFINITION_ID      TIME\n",
       "560966         984  measurement_1141  0.027321\n",
       "560967         984   observation_156  0.028739\n",
       "560968         984  measurement_1140  0.030802\n",
       "560969         984  measurement_1327  0.035081\n",
       "560970         984     condition_459  0.038022"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "frequencySelectionApplied = 0    # 0 = do not apply, 1 = do apply\n",
    "\n",
    "#selecting the standart dataset with no pre-selections\n",
    "data = pd.read_csv(\"data/synthetic_data_lung_cancer.csv\")\n",
    "\n",
    "#if frequency selection has been done:\n",
    "if frequencySelectionApplied == 1:\n",
    "    data = pd.read_csv(\"data/bestFrequencyFiltered_t-low-0.3_t-high-1.csv\") # adjust this import to match the result from the frequency_selection_jan notebook\n",
    "\n",
    "print(data.columns)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ded20a",
   "metadata": {},
   "source": [
    "Here we checked some data qualities and gained a better understanding of the data.<br>\n",
    "A significant amount of this work has unfortunately been lost, but there is the Visual_Exploratory.ipynb where some graphs are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7666277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DEFINITION_ID</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>condition_1922</td>\n",
       "      <td>0.008643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>condition_785</td>\n",
       "      <td>0.027792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>condition_1561</td>\n",
       "      <td>0.057292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>condition_2391</td>\n",
       "      <td>0.065500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>condition_175</td>\n",
       "      <td>0.166536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560922</th>\n",
       "      <td>984</td>\n",
       "      <td>condition_747</td>\n",
       "      <td>0.006456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560923</th>\n",
       "      <td>984</td>\n",
       "      <td>condition_1767</td>\n",
       "      <td>0.007445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560931</th>\n",
       "      <td>984</td>\n",
       "      <td>condition_517</td>\n",
       "      <td>0.008754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560964</th>\n",
       "      <td>984</td>\n",
       "      <td>condition_1496</td>\n",
       "      <td>0.023802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560970</th>\n",
       "      <td>984</td>\n",
       "      <td>condition_459</td>\n",
       "      <td>0.038022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127117 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SUBJECT_ID   DEFINITION_ID      TIME\n",
       "1                1  condition_1922  0.008643\n",
       "2                1   condition_785  0.027792\n",
       "5                1  condition_1561  0.057292\n",
       "7                1  condition_2391  0.065500\n",
       "8                1   condition_175  0.166536\n",
       "...            ...             ...       ...\n",
       "560922         984   condition_747  0.006456\n",
       "560923         984  condition_1767  0.007445\n",
       "560931         984   condition_517  0.008754\n",
       "560964         984  condition_1496  0.023802\n",
       "560970         984   condition_459  0.038022\n",
       "\n",
       "[127117 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['DEFINITION_ID'].str.contains('condition_*')]\n",
    "#all condition observations are removed due to frequency Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f426752",
   "metadata": {},
   "source": [
    "As a result we discovered that the frequency of DEFENITION_IDs corresponded to the types of DEFENITION_IDs. <br>\n",
    "This meant that frequency selection is not useful in reducing recurrent data and noise. <br>\n",
    "Therefore we concluded that maybe the recurrance of types of DEFENITION_IDs may have to be adjusted to have a fair comparison on the influence over the target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79030d4d",
   "metadata": {},
   "source": [
    "Going further we decided to stretch out the DEFENITION_ID into multiple features.<br>\n",
    "Both options for processing the data deliver the same final table with the difference being that the data format 0 has a seperate column for the actual IDs of the features [condition,procedure,drug,observation,measurement]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8f76d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New unique categorie: drug' 'New unique categorie: condition'\n",
      " 'New unique categorie: measurement' 'New unique categorie: observation'\n",
      " 'New unique categorie: procedure' 'New unique categorie: death']\n",
      "Index(['SUBJECT_ID', 'TIME', 'condition', 'death', 'drug', 'measurement',\n",
      "       'observation', 'procedure', 'time_since_last'],\n",
      "      dtype='object')\n",
      "Unique values in feature SUBJECT_ID: 727\n",
      "Unique values in feature TIME: 560956\n",
      "Unique values in feature condition: 2400\n",
      "Unique values in feature death: 2\n",
      "Unique values in feature drug: 419\n",
      "Unique values in feature measurement: 1333\n",
      "Unique values in feature observation: 225\n",
      "Unique values in feature procedure: 491\n",
      "Unique values in feature time_since_last: 560198\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>condition</th>\n",
       "      <th>death</th>\n",
       "      <th>drug</th>\n",
       "      <th>measurement</th>\n",
       "      <th>observation</th>\n",
       "      <th>procedure</th>\n",
       "      <th>time_since_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>1922</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.003836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>785</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.019149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032515</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>132</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.024250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID      TIME  condition  death  drug  measurement  observation  \\\n",
       "0           1  0.004807         -1      0   217           -1           -1   \n",
       "1           1  0.008643       1922      0    -1           -1           -1   \n",
       "2           1  0.027792        785      0    -1           -1           -1   \n",
       "3           1  0.032515         -1      0    49           -1           -1   \n",
       "4           1  0.056765         -1      0    -1          132           -1   \n",
       "\n",
       "   procedure  time_since_last  \n",
       "0         -1         0.000000  \n",
       "1         -1         0.003836  \n",
       "2         -1         0.019149  \n",
       "3         -1         0.004722  \n",
       "4         -1         0.024250  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFormat = 1 # 0 for seperate ID column 1 for not\n",
    "df = data.copy()\n",
    "if dataFormat == 0:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['DEFINITION_ID_encoded'] = label_encoder.fit_transform(df['DEFINITION_ID'])\n",
    "    df['condition'] = df['DEFINITION_ID'].apply(lambda x: 'condition' in x)\n",
    "    df['procedure'] = df['DEFINITION_ID'].apply(lambda x: 'procedure' in x)\n",
    "    df['drug'] = df['DEFINITION_ID'].apply(lambda x: 'drug' in x)\n",
    "    df['observation'] = df['DEFINITION_ID'].apply(lambda x: 'observation' in x)\n",
    "    df['measurement'] = df['DEFINITION_ID'].apply(lambda x: 'measurement' in x)\n",
    "    df.drop(columns=['DEFINITION_ID'], inplace=True)\n",
    "    df['time_since_last'] = df.groupby('SUBJECT_ID')['TIME'].diff().fillna(0)\n",
    "    columns_to_convert = ['condition', 'procedure', 'drug', 'observation', 'measurement']\n",
    "    for column in columns_to_convert:\n",
    "        df[column] = df[column].astype(int)\n",
    "    time_threshold = 1 \n",
    "    df['death'] = df['time_since_last'].apply(lambda x: 1 if x <= time_threshold else 0)\n",
    "elif dataFormat == 1:\n",
    "    # Splitting 'DEFINITION_ID' into multiple columns\n",
    "    new_cols = df['DEFINITION_ID'].str.split('_', expand=True)\n",
    "    # Naming the new columns\n",
    "    new_cols.columns = ['CATEGORY', 'CATEGORY_ID']\n",
    "    print(\"New unique categorie: \"+new_cols['CATEGORY'].unique())\n",
    "    # Pivoting the DataFrame\n",
    "    pivot_new_cols = new_cols.pivot_table(index=data.index, columns='CATEGORY', values='CATEGORY_ID', aggfunc=lambda x: ', '.join(str(v) for v in x)).fillna('-1')\n",
    "    # Concatenating the new columns to the original DataFrame\n",
    "    df = pd.concat([df, pivot_new_cols], axis=1)\n",
    "    # Dropping the original 'DEFINITION_ID' column\n",
    "    df.drop(columns=['DEFINITION_ID'], inplace=True)\n",
    "    # Filling the death column \n",
    "    df['death'] = df['death'].replace('None', '1')\n",
    "    df['death'] = df['death'].replace('-1', '0')\n",
    "    # Converting column to boolean dtype\n",
    "    df['death'] = df['death'].astype(int)\n",
    "    # Creating additional column\n",
    "    df['time_since_last'] = df.groupby('SUBJECT_ID')['TIME'].diff().fillna(0)\n",
    "    columns_to_convert = ['condition', 'measurement', 'procedure','drug','observation']\n",
    "    df[columns_to_convert] = df[columns_to_convert].astype(int, errors='ignore')\n",
    "else:\n",
    "    ...\n",
    "\n",
    "print(df.columns)\n",
    "#df.loc[(df['condition']=='')&(df['drug']=='')&(df['measurement']=='')&(df['observation']=='')&(df['procedure']=='')]\n",
    "[print(\"Unique values in feature \"+x+\": \"+str(len(df[x].unique()))) for x in df.columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe9dead",
   "metadata": {},
   "source": [
    "Here we also included a inversion of the target feature, because we initially thought that in this way we can predict if someone will not die in one year. (This is of course wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea207ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>condition</th>\n",
       "      <th>death</th>\n",
       "      <th>drug</th>\n",
       "      <th>measurement</th>\n",
       "      <th>observation</th>\n",
       "      <th>procedure</th>\n",
       "      <th>time_since_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.003836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>785</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.019149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032515</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>132</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.024250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID      TIME  condition  death  drug  measurement  observation  \\\n",
       "0           1  0.004807         -1      1   217           -1           -1   \n",
       "1           1  0.008643       1922      1    -1           -1           -1   \n",
       "2           1  0.027792        785      1    -1           -1           -1   \n",
       "3           1  0.032515         -1      1    49           -1           -1   \n",
       "4           1  0.056765         -1      1    -1          132           -1   \n",
       "\n",
       "   procedure  time_since_last  \n",
       "0         -1         0.000000  \n",
       "1         -1         0.003836  \n",
       "2         -1         0.019149  \n",
       "3         -1         0.004722  \n",
       "4         -1         0.024250  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetFeatureInversion = 1\n",
    "\n",
    "if targetFeatureInversion == 1:\n",
    "    df['death']=df['death'].map(lambda a:0 if a==1 else 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6837a36",
   "metadata": {},
   "source": [
    "Here we included the option to make all the categorical columns resulting from DEFINITION_ID one hot encoded. This of course means that we get around 54.000 columns. This usually blows any calculations, feature selections, fitting and so on out of proportion. Hence we advise not to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0880f6ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>condition</th>\n",
       "      <th>death</th>\n",
       "      <th>drug</th>\n",
       "      <th>measurement</th>\n",
       "      <th>observation</th>\n",
       "      <th>procedure</th>\n",
       "      <th>time_since_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.003836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>785</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.019149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032515</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>132</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.024250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID      TIME  condition  death  drug  measurement  observation  \\\n",
       "0           1  0.004807         -1      1   217           -1           -1   \n",
       "1           1  0.008643       1922      1    -1           -1           -1   \n",
       "2           1  0.027792        785      1    -1           -1           -1   \n",
       "3           1  0.032515         -1      1    49           -1           -1   \n",
       "4           1  0.056765         -1      1    -1          132           -1   \n",
       "\n",
       "   procedure  time_since_last  \n",
       "0         -1         0.000000  \n",
       "1         -1         0.003836  \n",
       "2         -1         0.019149  \n",
       "3         -1         0.004722  \n",
       "4         -1         0.024250  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummies for categorical analysis\n",
    "\n",
    "createDummies = 0 # 0 = no, 1 = yes\n",
    "\n",
    "if createDummies ==1 and dataFormat==1:\n",
    "    df = pd.get_dummies(df,columns=['condition','drug','measurement','observation','procedure'])\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396efcc8",
   "metadata": {},
   "source": [
    "Next we split the data into training and test data. This should be done along the SUBJECT_ID, because obviously a real world data set would only include the DEFINITION_IDs of one individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b871b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: death, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>condition</th>\n",
       "      <th>drug</th>\n",
       "      <th>measurement</th>\n",
       "      <th>observation</th>\n",
       "      <th>procedure</th>\n",
       "      <th>time_since_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>-1</td>\n",
       "      <td>217</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>1922</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.003836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>785</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.019149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032515</td>\n",
       "      <td>-1</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>132</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.024250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID      TIME  condition  drug  measurement  observation  procedure  \\\n",
       "0           1  0.004807         -1   217           -1           -1         -1   \n",
       "1           1  0.008643       1922    -1           -1           -1         -1   \n",
       "2           1  0.027792        785    -1           -1           -1         -1   \n",
       "3           1  0.032515         -1    49           -1           -1         -1   \n",
       "4           1  0.056765         -1    -1          132           -1         -1   \n",
       "\n",
       "   time_since_last  \n",
       "0         0.000000  \n",
       "1         0.003836  \n",
       "2         0.019149  \n",
       "3         0.004722  \n",
       "4         0.024250  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# List of unique SUBJECT_IDs\n",
    "unique_subject_ids = df['SUBJECT_ID'].unique()\n",
    "\n",
    "# Split the unique_subject_ids into train and test IDs\n",
    "train_ids, test_ids = train_test_split(unique_subject_ids, test_size=0.3, random_state=2)\n",
    "\n",
    "# Filter the main DataFrame into train and test sets based on the selected IDs\n",
    "train_data = df[df['SUBJECT_ID'].isin(train_ids)]\n",
    "test_data = df[df['SUBJECT_ID'].isin(test_ids)]\n",
    "\n",
    "# Separate the features (X) and target variable (y) for train and test sets\n",
    "X_train = train_data.drop('death',axis=1)# Drop 'SUBJECT_ID' and target column\n",
    "y_train = pd.Series(train_data.death)\n",
    "\n",
    "X_test = test_data.drop('death',axis=1)# Drop 'SUBJECT_ID' and target column\n",
    "y_test = pd.Series(test_data.death)\n",
    "\n",
    "if createDummies ==1 and dataFormat==1: # Here we have to account for nonsensical values\n",
    "    X_train = X_train.drop(['condition_-1','drug_-1','measurement_-1','observation_-1','procedure_-1'],axis=1)\n",
    "    X_test = X_test.drop(['condition_-1','drug_-1','measurement_-1','observation_-1','procedure_-1'],axis=1)\n",
    "#old way:\n",
    "#X = df.drop('death',axis=1).drop(['condition_-1','drug_-1','measurement_-1','observation_-1','procedure_-1'],axis=1)\n",
    "#y = pd.Series(df.death)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(y_train.head())\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c7d56",
   "metadata": {},
   "source": [
    "After the creation of the training and test data we tried to apply a sampling strategy. This unfortunately did not work as we imagined. This is because we wanted to balance the training set on every unique patient that survives or dies. This is not implemented yet correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f38bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing happened\n"
     ]
    }
   ],
   "source": [
    "#undersampling\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "useUnderSampeling = 0 # 0 = no, 1 = yes\n",
    "\n",
    "if useUnderSampeling == 1:\n",
    "    # Separate majority and minority classes\n",
    "    df_majority = df[df.death==0]\n",
    "    df_minority = df[df.death==1]\n",
    "    \n",
    "    # Downsample majority class\n",
    "    df_majority_downsampled = resample(df_majority,\n",
    "                                     replace=False,    # sample without replacement\n",
    "                                     n_samples=len(df_minority), # to match minority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    \n",
    "    # Combine minority class with downsampled majority class\n",
    "    df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "    \n",
    "    # Display new class counts\n",
    "    print(df_balanced.death.value_counts())\n",
    "    print([len(df_balanced.loc[df_balanced['death']==1]),len(df_balanced.loc[df_balanced['death']==0, 'SUBJECT_ID'].unique())])\n",
    "    \n",
    "    # Separate X_train and y_train after balancing\n",
    "    X_train_balanced = df_balanced.drop('death', axis=1)\n",
    "    y_train_balanced = df_balanced['death']\n",
    "    X_train = X_train_balanced\n",
    "    y_train = y_train_balanced\n",
    "else:\n",
    "    print(\"Nothing happened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c268c5e",
   "metadata": {},
   "source": [
    "This feature selection is only relevant for when the dummies for the DEFINITION_ID-categories are created. This is to improve the model performance for training. This unfortunately takes massive amounts of resources and is propably not even very meaningful, because the massive amount of categories results in alot of noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c6d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No feature selection, because of low feature count\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression  # Replace with an appropriate estimator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "if createDummies==1:\n",
    "\n",
    "#X_train_sparse = csr_matrix(X_train)\n",
    "\n",
    "    # Initialize your estimator \n",
    "    lr=LogisticRegression(penalty='l1',solver='liblinear')\n",
    "    svc=SVC(kernel=\"linear\")\n",
    "    nb=GaussianNB()\n",
    "    \n",
    "    estimator = lr  #change to whatever works best\n",
    "    \n",
    "    # Initialize RFECV with the estimator and scoring method\n",
    "    rfecv=RFECV(estimator=estimator, cv=5)\n",
    "    kbest=SelectKBest(score_func=f_classif, k=1000)\n",
    "    selector = kbest\n",
    "    \n",
    "    # Fit the selector on your training data\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    # Get selected feature indices\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "    \n",
    "    # Get the names of selected features\n",
    "    selected_feature_names = X_train.columns[selected_feature_indices]\n",
    "    \n",
    "    # Create DataFrame with selected features\n",
    "    X_train_selected_df = X_train[selected_feature_names]\n",
    "    \n",
    "    print(X_train_selected_df.head())\n",
    "else:\n",
    "    print(\"No feature selection, because of low feature count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b537ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no scaling necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e7b67",
   "metadata": {},
   "source": [
    "Here we apply preprocessing concerning dimensionality reduction techniques. We define a function which transfroms X_train and X_test into the desired format. <br>\n",
    "We tried PCA and MCA. For MCA we had to apply the dimensionality reduction on only the categorical values and afterwards join them back in. The amount of dimensions is freely choosable. On these you can even apply regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a919611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prince import MCA\n",
    "from sklearn.decomposition import PCA\n",
    "#pip install prince\n",
    "\n",
    "#applying MCA,PCA or others\n",
    "\n",
    "def applyDimensionalityReduction(reductionTargetTrain,reductionTargetTest,typeOfReduction,n_components):\n",
    "    if typeOfReduction == 'mca':\n",
    "        X_train_categorical = reductionTargetTrain.drop(columns=['TIME','time_since_last'], inplace=False)\n",
    "        X_test_categorical = reductionTargetTest.drop(columns=['TIME','time_since_last'], inplace=False)\n",
    "        reducer = MCA(n_components=n_components)\n",
    "        reducer.fit(X_train_categorical)\n",
    "        transformed_train = reducer.transform(X_train_categorical)\n",
    "        transformed_test = reducer.transform(X_test_categorical)\n",
    "        X_train_mca = pd.concat([reductionTargetTrain[['TIME','time_since_last']],transformed_train],axis=1)\n",
    "        X_test_mca = pd.concat([reductionTargetTest[['TIME','time_since_last']],transformed_test],axis=1)\n",
    "        return X_train_mca,X_test_mca\n",
    "    elif typeOfReduction =='pca':\n",
    "        reductionTargetTrain.columns = reductionTargetTrain.columns.astype(str)\n",
    "        reductionTargetTest.columns = reductionTargetTest.columns.astype(str)\n",
    "        reducer = PCA(n_components=n_components)\n",
    "        reducer.fit(reductionTargetTrain)\n",
    "        transformed_train = reducer.transform(reductionTargetTrain)\n",
    "        transformed_test = reducer.transform(reductionTargetTest)\n",
    "        return pd.DataFrame(transformed_train), pd.DataFrame(transformed_test)\n",
    "    else:\n",
    "        return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64536472",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 16.3 GiB for an array with shape (2191058688,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m reduction_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmca\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# choose 'mca','pca' or 'None'\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train_reduced,X_test_reduced \u001b[38;5;241m=\u001b[39m applyDimensionalityReduction(X_train,X_test,reduction_type,\u001b[38;5;241m2\u001b[39m) \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      6\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m X_train_reduced\n",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m, in \u001b[0;36mapplyDimensionalityReduction\u001b[1;34m(reductionTargetTrain, reductionTargetTest, typeOfReduction, n_components)\u001b[0m\n\u001b[0;32m     10\u001b[0m X_test_categorical \u001b[38;5;241m=\u001b[39m reductionTargetTest\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIME\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_since_last\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m reducer \u001b[38;5;241m=\u001b[39m MCA(n_components\u001b[38;5;241m=\u001b[39mn_components)\n\u001b[1;32m---> 12\u001b[0m reducer\u001b[38;5;241m.\u001b[39mfit(X_train_categorical)\n\u001b[0;32m     13\u001b[0m transformed_train \u001b[38;5;241m=\u001b[39m reducer\u001b[38;5;241m.\u001b[39mtransform(X_train_categorical)\n\u001b[0;32m     14\u001b[0m transformed_test \u001b[38;5;241m=\u001b[39m reducer\u001b[38;5;241m.\u001b[39mtransform(X_test_categorical)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\prince\\mca.py:36\u001b[0m, in \u001b[0;36mMCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJ_ \u001b[38;5;241m=\u001b[39m one_hot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Apply CA to the indicator matrix\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(one_hot)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\prince\\ca.py:82\u001b[0m, in \u001b[0;36mCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     80\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_masses_\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m     81\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_masses_\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m---> 82\u001b[0m S \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mdiags(r\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m@\u001b[39m (X \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(r, c)) \u001b[38;5;241m@\u001b[39m sparse\u001b[38;5;241m.\u001b[39mdiags(c\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Compute SVD on the standardised residuals\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvd_ \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mcompute_svd(\n\u001b[0;32m     86\u001b[0m     X\u001b[38;5;241m=\u001b[39mS,\n\u001b[0;32m     87\u001b[0m     n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components, \u001b[38;5;28mmin\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine,\n\u001b[0;32m     91\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\scipy\\sparse\\_base.py:630\u001b[0m, in \u001b[0;36m_spbase.__rmatmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    629\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rmul_dispatch(other)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\scipy\\sparse\\_base.py:608\u001b[0m, in \u001b[0;36m_spbase._rmul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    607\u001b[0m     tr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(other)\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m--> 608\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose()\u001b[38;5;241m.\u001b[39m_mul_dispatch(tr)\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\scipy\\sparse\\_base.py:526\u001b[0m, in \u001b[0;36m_spbase._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_vector(other\u001b[38;5;241m.\u001b[39mravel())\u001b[38;5;241m.\u001b[39mreshape(M, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m N:\n\u001b[1;32m--> 526\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_multivector(other)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_scalar(other)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\scipy\\sparse\\_base.py:594\u001b[0m, in \u001b[0;36m_spbase._mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mul_multivector\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtocsr()\u001b[38;5;241m.\u001b[39m_mul_multivector(other)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\IntroductionToDataScience\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:502\u001b[0m, in \u001b[0;36m_cs_matrix._mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# csr_matvecs or csc_matvecs\u001b[39;00m\n\u001b[0;32m    500\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matvecs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    501\u001b[0m fn(M, N, n_vecs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m--> 502\u001b[0m    other\u001b[38;5;241m.\u001b[39mravel(), result\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 16.3 GiB for an array with shape (2191058688,) and data type float64"
     ]
    }
   ],
   "source": [
    "reduction_type = 'mca' # choose 'mca','pca' or 'None'\n",
    "\n",
    "X_train_reduced,X_test_reduced = applyDimensionalityReduction(X_train,X_test,reduction_type,2) \n",
    "\n",
    "if 1:\n",
    "    X_train = X_train_reduced\n",
    "    X_test = X_test_reduced\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757214ec",
   "metadata": {},
   "source": [
    "Here is the most important part of the workflow. The models are instatiated and selected for fitting.<br>\n",
    "For some models we have hyperparameter tuning implemented. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57029054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "gSearch = 0 # select 0 or 1 if it should be executed or not (takes about 5 minutes)\n",
    "grid_search = None\n",
    "#Grid searches:\n",
    "if gSearch == 1: \n",
    "    #grid search for XGB\n",
    "    xgb_model = XGBClassifier(random_state=42)\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.1, 0.01, 0.05],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'subsample': [0.8, 0.9, 1],\n",
    "        'colsample_bytree': [0.3, 0.7, 1]\n",
    "    }\n",
    "    grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='roc_auc', cv=3, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "else:\n",
    "    ...\n",
    "\n",
    "# model\n",
    "log_reg = LogisticRegression(C=1.0, solver='liblinear', random_state=42)\n",
    "lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=50,criterion=\"gini\",max_features=100,max_depth=4)\n",
    "ada_boost_classifier = AdaBoostClassifier(base_estimator=rf, n_estimators=50, random_state=42)\n",
    "svc = SVC(kernel=\"linear\", probability=True)\n",
    "xgb = XGBClassifier(random_state=42) if gSearch == 0 else grid_search.best_estimator_\n",
    "\n",
    "all_models=[log_reg,lgbm,rf,ada_boost_classifier,svc,xgb]\n",
    "\n",
    "if(reduction_type == 'mca'or reduction_type == 'pca'):\n",
    "    print(\"Regression models are applicable.\")\n",
    "\n",
    "model = svc # select desired model\n",
    "\n",
    "#fit model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c8364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Limit the number of features to display\n",
    "top_n = len(X_train.columns) if len(X_train.columns)<=100 else 100\n",
    "indices = indices[:top_n]\n",
    "feature_importances = feature_importances[indices]\n",
    "feature_names = feature_names[indices]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title(\"Top \"+str(top_n)+\" Feature Importances\")\n",
    "plt.bar(range(top_n), feature_importances, align=\"center\")\n",
    "plt.xticks(range(top_n), feature_names, rotation=90)\n",
    "plt.xlabel(\"Feature Names\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5fca7",
   "metadata": {},
   "source": [
    "Here we implemented cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5261a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5)#, shuffle=True, random_state=42\n",
    "\n",
    "#cross validation\n",
    "scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc9cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b099fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "probs = pd.DataFrame(probs)\n",
    "y_pred_proba = pd.Series(probs.iloc[:, 1])\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test.values, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred = np.where(y_pred_proba >= threshold, 1, 0)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(f\"ROC AUC Score: {auc:.2f}\")\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('graphs/linearSVC_nofrequency_noSampling_MCA.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efccebe",
   "metadata": {},
   "source": [
    "Here is a iterative generation of images with the AUC for different models.<br>\n",
    "Not yet implemented!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f028fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc1e8967",
   "metadata": {},
   "source": [
    "Tools used:<br>\n",
    "- ChatGPT (this is due to our inexperience with complex python data processing, model training and plotting)<br>\n",
    "\n",
    "Sources used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89463f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
